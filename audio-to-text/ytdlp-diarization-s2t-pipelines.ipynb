{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTubeダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画のリンクのリスト → 音声ファイル\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "youtube_links = [\n",
    "    \"https://www.youtube.com/watch?v=xVmShH0-9xY\"\n",
    "]\n",
    "\n",
    "output_dir = \"src\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for link in youtube_links:\n",
    "    output_template = os.path.join(output_dir, \"%(title)s.%(ext)s\")\n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-x\",\n",
    "        \"--audio-format\", \"wav\", # 動画を取得したければこの行をコメントアウト\n",
    "        \"-o\", output_template,\n",
    "        link\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"✅ 成功:\", link)\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ 失敗:\", link)\n",
    "        print(\"標準エラー出力:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再生リストのリンクのリスト → 音声ファイル\n",
    "import os\n",
    "\n",
    "youtube_playlist_links = [\n",
    "    \"https://youtube.com/playlist?list=PLsbq1qh5ApJK0vcKhSkZfWyRBW82NzSRr&si=VnOYmKQyrzXc9bZ9\"\n",
    "] \n",
    "\n",
    "# 出力ディレクトリの作成\n",
    "output_dir = \"src\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 各リンクに対して音声をダウンロード\n",
    "for link in youtube_playlist_links:\n",
    "    # os.system(f'yt-dlp -x --audio-format wav -o \"{output_dir}/%(title)s.%(ext)s\" {link}')\n",
    "    # os.system(f'yt-dlp -x --audio-format mp3 -o \"{output_dir}/%(title)s.%(ext)s\" {link}')\n",
    "    os.system(f'yt-dlp -o \"{output_dir}/%(title)s.%(ext)s\" {link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字起こし & 話者分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインストールとモデルのロード\n",
    "import torch\n",
    "from pyannote.audio import Pipeline as PyannotePipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 話者分離モデル(pyannote.audio)のパイプライン設定\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "PYANNOTE_AUTH_TOKEN = os.getenv(\"PYANNOTE_AUTH_TOKEN\")\n",
    "pyannote_pipeline = PyannotePipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=PYANNOTE_AUTH_TOKEN,\n",
    ")\n",
    "pyannote_pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "# GPU用の設定\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# 音声認識モデル(whisper-large-v3)のロード\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline as transformers_pipeline\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "transformers_pipe = transformers_pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=256,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=\"word\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "folder_path = \"src\"\n",
    "output_dir = \"dst/speech-recognition\"\n",
    "\n",
    "for file_path in os.listdir(folder_path):\n",
    "    if file_path.endswith(\".mp3\"):\n",
    "        full_path = os.path.join(folder_path, file_path)\n",
    "        print(full_path)\n",
    "\n",
    "        try:\n",
    "            tmp_result = transformers_pipe(full_path, generate_kwargs={\"language\": \"english\"})\n",
    "            file_name = os.path.splitext(file_path)[0]\n",
    "\n",
    "            with open(os.path.join(output_dir, file_name + \"-text.csv\"), \"w\", encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"start\", \"end\", \"text\"])\n",
    "                for chunk in tmp_result[\"chunks\"]:\n",
    "                    writer.writerow([chunk[\"timestamp\"][0], chunk[\"timestamp\"][1], chunk[\"text\"]])\n",
    "            \n",
    "            del tmp_result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"エラーが発生しました: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 話者分類\n",
    "input_dir = \"src\"\n",
    "output_dir = \"dst/diarization\"\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".wav\"):\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        diarization = pyannote_pipeline(file_path)\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}-asr.csv\")\n",
    "        \n",
    "        with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"start\", \"end\", \"speaker\"])\n",
    "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                writer.writerow([round(turn.start, 2), round(turn.end, 2), speaker])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
