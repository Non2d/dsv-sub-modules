{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f914aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== データ概要 =====\n",
      "サンプル数: 20\n",
      "特徴量: ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
      "\n",
      "評価値の分布:\n",
      "平均: 2.525\n",
      "標準偏差: 0.638\n",
      "最小値: 2.000\n",
      "最大値: 4.000\n",
      "\n",
      "===== Leave-One-Out交差検証実行中 =====\n",
      "\n",
      "===== 各モデルの性能評価 =====\n",
      "モデル             RMSE       MAE       \n",
      "-----------------------------------\n",
      "重回帰分析           0.4295     0.3068    \n",
      "Ridge回帰         0.5229     0.3673    \n",
      "Lasso回帰         0.4721     0.3237    \n",
      "\n",
      "===== 各特徴量の回帰係数 =====\n",
      "\n",
      "重回帰分析:\n",
      "  切片: -0.0636\n",
      "  1-distance_v1: 1.4965\n",
      "  1-interval_v1: 1.0874\n",
      "  order_v1: 0.7743\n",
      "  rally_v1: 1.4542\n",
      "\n",
      "Ridge回帰:\n",
      "  切片: 1.3624\n",
      "  1-distance_v1: 0.6311\n",
      "  1-interval_v1: 0.6770\n",
      "  order_v1: 0.2791\n",
      "  rally_v1: 0.5691\n",
      "\n",
      "Lasso回帰:\n",
      "  切片: 0.5188\n",
      "  1-distance_v1: 1.2492\n",
      "  1-interval_v1: 0.9883\n",
      "  order_v1: 0.4506\n",
      "  rally_v1: 1.0715\n",
      "\n",
      "===== 予測精度の詳細分析 =====\n",
      "最も精度の高いモデル: 重回帰分析\n",
      "重回帰分析の相関係数: 0.7284\n",
      "Ridge回帰の相関係数: 0.6123\n",
      "Lasso回帰の相関係数: 0.6577\n",
      "\n",
      "===== 予測誤差の分析 =====\n",
      "平均誤差: 0.0295\n",
      "誤差の標準偏差: 0.4285\n",
      "最大過大評価: 1.0557\n",
      "最大過小評価: -0.8424\n",
      "\n",
      "===== 特徴量の重要度 =====\n",
      "1-distance_v1: 0.311\n",
      "1-interval_v1: 0.226\n",
      "order_v1: 0.161\n",
      "rally_v1: 0.302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CSVファイルを読み込み\n",
    "# df = pd.read_csv('../data/src/structural-features.csv')\n",
    "df = pd.read_csv('motion_title_content_with_graphs-gpt-a.csv')\n",
    "\n",
    "# 特徴量と目的変数を分離\n",
    "feature_columns = ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
    "X = df[feature_columns]\n",
    "y = df['average_evaluation']\n",
    "\n",
    "print(\"===== データ概要 =====\")\n",
    "print(f\"サンプル数: {len(df)}\")\n",
    "print(f\"特徴量: {feature_columns}\")\n",
    "print(f\"\\n評価値の分布:\")\n",
    "print(f\"平均: {y.mean():.3f}\")\n",
    "print(f\"標準偏差: {y.std():.3f}\")\n",
    "print(f\"最小値: {y.min():.3f}\")\n",
    "print(f\"最大値: {y.max():.3f}\")\n",
    "\n",
    "# Leave-One-Out交差検証の準備\n",
    "loo = LeaveOneOut()\n",
    "n_samples = len(X)\n",
    "\n",
    "# 各モデルの結果を格納する辞書\n",
    "results = {\n",
    "    '重回帰分析': {'predictions': [], 'model': LinearRegression()},\n",
    "    'Ridge回帰': {'predictions': [], 'model': Ridge(alpha=1.0)},\n",
    "    'Lasso回帰': {'predictions': [], 'model': Lasso(alpha=0.01)}\n",
    "}\n",
    "\n",
    "# Leave-One-Out交差検証の実行\n",
    "print(\"\\n===== Leave-One-Out交差検証実行中 =====\")\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # 各モデルで学習と予測\n",
    "    for model_name, model_info in results.items():\n",
    "        model = model_info['model']\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_info['predictions'].append(y_pred[0])\n",
    "\n",
    "# 評価指標の計算\n",
    "print(\"\\n===== 各モデルの性能評価 =====\")\n",
    "print(f\"{'モデル':<15} {'RMSE':<10} {'MAE':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for model_name, model_info in results.items():\n",
    "    predictions = np.array(model_info['predictions'])\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    \n",
    "    print(f\"{model_name:<15} {rmse:<10.4f} {mae:<10.4f}\")\n",
    "    \n",
    "    # 結果を保存\n",
    "    model_info['rmse'] = rmse\n",
    "    model_info['mae'] = mae\n",
    "\n",
    "# 全データで各モデルを学習して係数を確認\n",
    "print(\"\\n===== 各特徴量の回帰係数 =====\")\n",
    "\n",
    "for model_name, model_info in results.items():\n",
    "    model = model_info['model']\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  切片: {model.intercept_:.4f}\")\n",
    "    for i, feature in enumerate(feature_columns):\n",
    "        print(f\"  {feature}: {model.coef_[i]:.4f}\")\n",
    "\n",
    "# 予測値と実測値の相関\n",
    "print(\"\\n===== 予測精度の詳細分析 =====\")\n",
    "best_model_name = min(results, key=lambda x: results[x]['rmse'])\n",
    "print(f\"最も精度の高いモデル: {best_model_name}\")\n",
    "\n",
    "# 実測値と予測値の相関係数\n",
    "for model_name, model_info in results.items():\n",
    "    predictions = np.array(model_info['predictions'])\n",
    "    correlation = np.corrcoef(y, predictions)[0, 1]\n",
    "    print(f\"{model_name}の相関係数: {correlation:.4f}\")\n",
    "\n",
    "# 予測誤差の分析\n",
    "print(\"\\n===== 予測誤差の分析 =====\")\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "errors = y - best_predictions\n",
    "\n",
    "print(f\"平均誤差: {np.mean(errors):.4f}\")\n",
    "print(f\"誤差の標準偏差: {np.std(errors):.4f}\")\n",
    "print(f\"最大過大評価: {np.max(errors):.4f}\")\n",
    "print(f\"最大過小評価: {np.min(errors):.4f}\")\n",
    "\n",
    "# 各特徴量の重要度（係数の絶対値）\n",
    "print(\"\\n===== 特徴量の重要度 =====\")\n",
    "model = results['重回帰分析']['model']\n",
    "model.fit(X, y)\n",
    "feature_importance = np.abs(model.coef_)\n",
    "feature_importance_normalized = feature_importance / np.sum(feature_importance)\n",
    "\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"{feature}: {feature_importance_normalized[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf1d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    110\u001b[39m     plt.show()\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# 使用例\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mcreate_scatter_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m create_overlay_scatter_plot(X, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcreate_scatter_plots\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train_idx, test_idx \u001b[38;5;129;01min\u001b[39;00m loo.split(X):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         X_train, X_test = \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m, X[test_idx]\n\u001b[32m     29\u001b[39m         y_train, y_test = y[train_idx], y[test_idx]\n\u001b[32m     31\u001b[39m         model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Koteh\\Desktop\\CodeStudy\\dsv-sub-modules\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Koteh\\Desktop\\CodeStudy\\dsv-sub-modules\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Koteh\\Desktop\\CodeStudy\\dsv-sub-modules\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "\n",
    "# データの読み込み\n",
    "# CSVファイルからデータを読み込む場合\n",
    "df = pd.read_csv('your_data.csv')  # ファイル名を実際のものに変更してください\n",
    "\n",
    "# 特徴量の列名（実際の列名に変更してください）\n",
    "feature_columns = ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
    "target_column = 'evaluation_score'  # 評価値の列名\n",
    "\n",
    "# X: 特徴量行列 (20サンプル × 4特徴量)\n",
    "X = df[feature_columns].values\n",
    "\n",
    "# y: 評価値ベクトル (20サンプル)\n",
    "y = df[target_column].values\n",
    "\n",
    "def create_scatter_plots(X, y):\n",
    "    \"\"\"\n",
    "    3つの回帰モデルの予測値vs実際値の散布図を作成\n",
    "    \"\"\"\n",
    "    # モデルの定義\n",
    "    models = {\n",
    "        'Multiple Linear': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),  # デフォルト値、GridSearchCVで最適化可能\n",
    "        'Lasso': Lasso(alpha=0.01)   # 小さめの値に調整（0.1だと係数が0になりすぎる可能性）\n",
    "    }\n",
    "    \n",
    "    # Leave-One-Out交差検証\n",
    "    loo = LeaveOneOut()\n",
    "    predictions = {name: np.zeros(len(y)) for name in models}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            predictions[name][test_idx] = model.predict(X_test)\n",
    "    \n",
    "    # 散布図の作成\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    for idx, (name, pred) in enumerate(predictions.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 散布図をプロット\n",
    "        ax.scatter(y, pred, alpha=0.6, s=50)\n",
    "        \n",
    "        # y=xの対角線を追加\n",
    "        min_val = min(y.min(), pred.min())\n",
    "        max_val = max(y.max(), pred.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], \n",
    "                'k--', alpha=0.5, label='Perfect prediction')\n",
    "        \n",
    "        # 相関係数を計算して表示\n",
    "        corr = np.corrcoef(y, pred)[0, 1]\n",
    "        ax.text(0.05, 0.95, f'r = {corr:.3f}', \n",
    "                transform=ax.transAxes, verticalalignment='top')\n",
    "        \n",
    "        # ラベルとタイトル\n",
    "        ax.set_xlabel('Actual evaluation score')\n",
    "        ax.set_ylabel('Predicted score')\n",
    "        ax.set_title(f'{name} Regression')\n",
    "        ax.set_xlim(1.5, 4.5)\n",
    "        ax.set_ylim(1.5, 4.5)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('regression_scatter_plots.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 別の可視化方法：重ね合わせ版\n",
    "def create_overlay_scatter_plot(X, y):\n",
    "    \"\"\"\n",
    "    3つのモデルの結果を1つの図に重ね合わせる\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'Multiple Linear': (LinearRegression(), 'blue', 'o'),\n",
    "        'Ridge': (Ridge(alpha=1.0), 'red', 's'),\n",
    "        'Lasso': (Lasso(alpha=0.1), 'green', '^')\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    for name, (model, color, marker) in models.items():\n",
    "        loo = LeaveOneOut()\n",
    "        predictions = np.zeros(len(y))\n",
    "        \n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            predictions[test_idx] = model.predict(X_test)\n",
    "        \n",
    "        plt.scatter(y, predictions, alpha=0.6, s=50, \n",
    "                   color=color, marker=marker, label=name)\n",
    "    \n",
    "    # y=xの対角線\n",
    "    min_val = 1.5\n",
    "    max_val = 4.5\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \n",
    "             'k--', alpha=0.5, label='Perfect prediction')\n",
    "    \n",
    "    plt.xlabel('Actual evaluation score')\n",
    "    plt.ylabel('Predicted score')\n",
    "    plt.title('Regression Model Predictions')\n",
    "    plt.xlim(1.5, 4.5)\n",
    "    plt.ylim(1.5, 4.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.gca().set_aspect('equal')\n",
    "    \n",
    "    plt.savefig('regression_overlay_plot.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 使用例\n",
    "# create_scatter_plots(X, y)\n",
    "# create_overlay_scatter_plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986bb27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 重回帰分析の正しい理解 =====\n",
      "\n",
      "【1】全データで学習・全データで評価（過学習の例）\n",
      "切片: 0.6952\n",
      "1-distance_v1: 1.1180\n",
      "1-interval_v1: 0.5201\n",
      "order_v1: 0.1864\n",
      "rally_v1: 1.5329\n",
      "\n",
      "相関係数: 0.6114\n",
      "RMSE: 0.5307\n",
      "※これは訓練データと同じデータで評価しているので、実際の性能より良く見える\n",
      "\n",
      "\n",
      "【2】Leave-One-Out交差検証（実際の性能）\n",
      "相関係数: 0.2918\n",
      "RMSE: 0.6761\n",
      "\n",
      "各特徴量の重みの変動（20回の交差検証）:\n",
      "1-distance_v1: 平均=1.111, 標準偏差=0.237\n",
      "1-interval_v1: 平均=0.515, 標準偏差=0.117\n",
      "order_v1: 平均=0.180, 標準偏差=0.168\n",
      "rally_v1: 平均=1.526, 標準偏差=0.181\n",
      "\n",
      "\n",
      "【3】異なる重み設定での性能比較（交差検証）\n",
      "\n",
      "重み設定ごとの交差検証性能:\n",
      "設定                   相関係数       RMSE      \n",
      "----------------------------------------\n",
      "すべて1                 0.2677     0.6584    \n",
      "rally重視              0.4540     0.6047    \n",
      "distance重視           0.3472     0.6361    \n",
      "正規化（合計4）             0.4383     0.6105    \n",
      "最適化（制約なし）            0.2918     0.6761    \n",
      "\n",
      "\n",
      "【4】なぜ重み=1が意外と良いのか？\n",
      "\n",
      "特徴量の統計:\n",
      "特徴量                  平均         標準偏差      \n",
      "----------------------------------------\n",
      "1-distance_v1        0.437      0.182     \n",
      "1-interval_v1        0.573      0.326     \n",
      "order_v1             0.605      0.219     \n",
      "rally_v1             0.580      0.189     \n",
      "\n",
      "→ 各特徴量の平均・分散が似ているため、重み=1でもある程度機能する\n",
      "→ しかし最適化すると、わずかに性能が向上（0.2677→0.2918）\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# データ読み込み\n",
    "df = pd.read_csv('../data/src/structural-features.csv')\n",
    "feature_columns = ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
    "X = df[feature_columns]\n",
    "y = df['average_evaluation']\n",
    "\n",
    "print(\"===== 重回帰分析の正しい理解 =====\\n\")\n",
    "\n",
    "# 1. 全データで学習した場合（これは実際には使えない）\n",
    "print(\"【1】全データで学習・全データで評価（過学習の例）\")\n",
    "lr_all = LinearRegression()\n",
    "lr_all.fit(X, y)\n",
    "y_pred_all = lr_all.predict(X)\n",
    "\n",
    "print(f\"切片: {lr_all.intercept_:.4f}\")\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    print(f\"{feat}: {lr_all.coef_[i]:.4f}\")\n",
    "\n",
    "corr_all = pearsonr(y_pred_all, y)[0]\n",
    "rmse_all = np.sqrt(mean_squared_error(y, y_pred_all))\n",
    "print(f\"\\n相関係数: {corr_all:.4f}\")\n",
    "print(f\"RMSE: {rmse_all:.4f}\")\n",
    "print(\"※これは訓練データと同じデータで評価しているので、実際の性能より良く見える\")\n",
    "\n",
    "# 2. Leave-One-Out交差検証（実際の性能）\n",
    "print(\"\\n\\n【2】Leave-One-Out交差検証（実際の性能）\")\n",
    "loo = LeaveOneOut()\n",
    "predictions = []\n",
    "all_weights = []\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # 19個のデータで学習\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # 残り1個で予測\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    \n",
    "    # 各fold での重みを記録\n",
    "    all_weights.append(lr.coef_)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "corr_loo = pearsonr(predictions, y)[0]\n",
    "rmse_loo = np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "print(f\"相関係数: {corr_loo:.4f}\")\n",
    "print(f\"RMSE: {rmse_loo:.4f}\")\n",
    "\n",
    "# 重みの変動を確認\n",
    "all_weights = np.array(all_weights)\n",
    "print(\"\\n各特徴量の重みの変動（20回の交差検証）:\")\n",
    "for i, feat in enumerate(feature_columns):\n",
    "    print(f\"{feat}: 平均={np.mean(all_weights[:, i]):.3f}, 標準偏差={np.std(all_weights[:, i]):.3f}\")\n",
    "\n",
    "# 3. 重み制約による比較\n",
    "print(\"\\n\\n【3】異なる重み設定での性能比較（交差検証）\")\n",
    "\n",
    "def evaluate_weights(X, y, weights=None, use_intercept=True):\n",
    "    \"\"\"指定された重みでの交差検証性能を評価\"\"\"\n",
    "    loo = LeaveOneOut()\n",
    "    predictions = []\n",
    "    \n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        if weights is None:\n",
    "            # 通常の重回帰\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(X_train, y_train)\n",
    "            y_pred = lr.predict(X_test)\n",
    "        else:\n",
    "            # 固定重みの場合\n",
    "            X_weighted = X_test @ weights\n",
    "            if use_intercept:\n",
    "                # 切片だけ最適化\n",
    "                lr = LinearRegression()\n",
    "                lr.fit((X_train @ weights).values.reshape(-1, 1), y_train)\n",
    "                y_pred = lr.predict(X_weighted.values.reshape(-1, 1))\n",
    "            else:\n",
    "                y_pred = X_weighted\n",
    "        \n",
    "        predictions.append(y_pred[0] if hasattr(y_pred, '__len__') else y_pred)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    return pearsonr(predictions, y)[0], np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "# 異なる重み設定を試す\n",
    "test_cases = [\n",
    "    (\"すべて1\", np.array([1, 1, 1, 1])),\n",
    "    (\"rally重視\", np.array([0.5, 0.5, 0.5, 2])),\n",
    "    (\"distance重視\", np.array([2, 0.5, 0.5, 0.5])),\n",
    "    (\"正規化（合計4）\", np.array([1.2, 1.0, 0.3, 1.5])),\n",
    "    (\"最適化（制約なし）\", None)\n",
    "]\n",
    "\n",
    "print(\"\\n重み設定ごとの交差検証性能:\")\n",
    "print(f\"{'設定':<20} {'相関係数':<10} {'RMSE':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, weights in test_cases:\n",
    "    corr, rmse = evaluate_weights(X, y, weights)\n",
    "    print(f\"{name:<20} {corr:<10.4f} {rmse:<10.4f}\")\n",
    "\n",
    "# 4. なぜ単純な重みが意外と良いのか\n",
    "print(\"\\n\\n【4】なぜ重み=1が意外と良いのか？\")\n",
    "print(\"\\n特徴量の統計:\")\n",
    "print(f\"{'特徴量':<20} {'平均':<10} {'標準偏差':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for feat in feature_columns:\n",
    "    print(f\"{feat:<20} {X[feat].mean():<10.3f} {X[feat].std():<10.3f}\")\n",
    "\n",
    "print(\"\\n→ 各特徴量の平均・分散が似ているため、重み=1でもある程度機能する\")\n",
    "print(\"→ しかし最適化すると、わずかに性能が向上（0.2677→0.2918）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03bc143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 特徴量の基本統計 =====\n",
      "       1-distance_v1  1-interval_v1   order_v1   rally_v1\n",
      "count      20.000000      20.000000  20.000000  20.000000\n",
      "mean        0.437041       0.573269   0.604745   0.579683\n",
      "std         0.182180       0.325688   0.219043   0.189495\n",
      "min         0.000000       0.000000   0.230179   0.206478\n",
      "25%         0.357639       0.247405   0.418330   0.480521\n",
      "50%         0.447222       0.595089   0.571207   0.556381\n",
      "75%         0.532366       0.882295   0.775363   0.653846\n",
      "max         0.843750       1.000000   1.000000   1.000000\n",
      "\n",
      "===== 方法1: 全ての重みを1にした場合 =====\n",
      "予測値 = 1×(1-distance) + 1×(1-interval) + 1×order + 1×rally\n",
      "相関係数: 0.4574\n",
      "RMSE: 0.6796\n",
      "予測値の範囲: 1.28 ~ 3.29\n",
      "実際の評価の範囲: 1.67 ~ 4.00\n",
      "\n",
      "===== 方法2: 重みを1 + 最適な切片と係数 =====\n",
      "予測値 = 1.015 + 0.669 × (特徴量の合計)\n",
      "相関係数: 0.4574\n",
      "RMSE: 0.5963\n",
      "\n",
      "===== 方法3: Leave-One-Outで重みを1の場合 =====\n",
      "相関係数: 0.2677\n",
      "RMSE: 0.6584\n",
      "\n",
      "===== 特徴量間の相関 =====\n",
      "               1-distance_v1  1-interval_v1  order_v1  rally_v1\n",
      "1-distance_v1          1.000         -0.168    -0.093     0.324\n",
      "1-interval_v1         -0.168          1.000     0.277     0.034\n",
      "order_v1              -0.093          0.277     1.000    -0.490\n",
      "rally_v1               0.324          0.034    -0.490     1.000\n",
      "\n",
      "===== まとめ =====\n",
      "単純な重み1での相関: 0.4574\n",
      "スケール調整後の相関: 0.4574\n",
      "LOO交差検証での相関: 0.2677\n",
      "最適化された重回帰の相関: 0.2918（前の結果より）\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# CSVファイルを読み込み\n",
    "df = pd.read_csv('../data/src/structural-features.csv')\n",
    "\n",
    "# 特徴量と目的変数を分離\n",
    "feature_columns = ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
    "X = df[feature_columns]\n",
    "y = df['average_evaluation']\n",
    "\n",
    "print(\"===== 特徴量の基本統計 =====\")\n",
    "print(X.describe())\n",
    "\n",
    "# 方法1: 全ての重みを1にした場合\n",
    "print(\"\\n===== 方法1: 全ての重みを1にした場合 =====\")\n",
    "# 単純な合計\n",
    "simple_sum = X.sum(axis=1)\n",
    "correlation_simple = pearsonr(simple_sum, y)[0]\n",
    "rmse_simple = np.sqrt(mean_squared_error(y, simple_sum))\n",
    "\n",
    "print(f\"予測値 = 1×(1-distance) + 1×(1-interval) + 1×order + 1×rally\")\n",
    "print(f\"相関係数: {correlation_simple:.4f}\")\n",
    "print(f\"RMSE: {rmse_simple:.4f}\")\n",
    "print(f\"予測値の範囲: {simple_sum.min():.2f} ~ {simple_sum.max():.2f}\")\n",
    "print(f\"実際の評価の範囲: {y.min():.2f} ~ {y.max():.2f}\")\n",
    "\n",
    "# 方法2: 重みを1にして、切片を追加（線形変換）\n",
    "print(\"\\n===== 方法2: 重みを1 + 最適な切片と係数 =====\")\n",
    "# 線形回帰で切片とスケールを最適化\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_simple = LinearRegression()\n",
    "lr_simple.fit(simple_sum.values.reshape(-1, 1), y)\n",
    "pred_simple_scaled = lr_simple.predict(simple_sum.values.reshape(-1, 1))\n",
    "correlation_scaled = pearsonr(pred_simple_scaled, y)[0]\n",
    "rmse_scaled = np.sqrt(mean_squared_error(y, pred_simple_scaled))\n",
    "\n",
    "print(f\"予測値 = {lr_simple.intercept_:.3f} + {lr_simple.coef_[0]:.3f} × (特徴量の合計)\")\n",
    "print(f\"相関係数: {correlation_scaled:.4f}\")\n",
    "print(f\"RMSE: {rmse_scaled:.4f}\")\n",
    "\n",
    "# 方法3: Leave-One-Outで重みを1にした場合の性能\n",
    "print(\"\\n===== 方法3: Leave-One-Outで重みを1の場合 =====\")\n",
    "loo = LeaveOneOut()\n",
    "predictions_simple = []\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # 訓練データで単純合計を計算\n",
    "    train_sum = X_train.sum(axis=1)\n",
    "    test_sum = X_test.sum(axis=1)\n",
    "    \n",
    "    # スケーリング係数を学習\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train_sum.values.reshape(-1, 1), y_train)\n",
    "    \n",
    "    # テストデータで予測\n",
    "    y_pred = lr.predict(test_sum.values.reshape(-1, 1))\n",
    "    predictions_simple.append(y_pred[0])\n",
    "\n",
    "correlation_loo_simple = pearsonr(predictions_simple, y)[0]\n",
    "rmse_loo_simple = np.sqrt(mean_squared_error(y, predictions_simple))\n",
    "\n",
    "print(f\"相関係数: {correlation_loo_simple:.4f}\")\n",
    "print(f\"RMSE: {rmse_loo_simple:.4f}\")\n",
    "\n",
    "# 特徴量間の相関を確認\n",
    "print(\"\\n===== 特徴量間の相関 =====\")\n",
    "feature_corr = X.corr()\n",
    "print(feature_corr.round(3))\n",
    "\n",
    "print(\"\\n===== まとめ =====\")\n",
    "print(f\"単純な重み1での相関: {correlation_simple:.4f}\")\n",
    "print(f\"スケール調整後の相関: {correlation_scaled:.4f}\")\n",
    "print(f\"LOO交差検証での相関: {correlation_loo_simple:.4f}\")\n",
    "print(f\"最適化された重回帰の相関: 0.2918（前の結果より）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072c4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== データ概要 =====\n",
      "サンプル数: 20\n",
      "特徴量: ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
      "\n",
      "評価値の分布:\n",
      "平均: 2.525\n",
      "標準偏差: 0.638\n",
      "最小値: 2.000\n",
      "最大値: 4.000\n",
      "\n",
      "===== Leave-One-Out交差検証実行中 =====\n",
      "\n",
      "===== 各モデルの性能評価 =====\n",
      "モデル             RMSE       MAE       \n",
      "-----------------------------------\n",
      "重回帰分析           0.4295     0.3068    \n",
      "Ridge回帰         0.4301     0.3078    \n",
      "Lasso回帰         0.4337     0.3104    \n",
      "\n",
      "===== 各特徴量の回帰係数 =====\n",
      "\n",
      "重回帰分析:\n",
      "  切片: 2.5250\n",
      "  1-distance_v1: 0.2657\n",
      "  1-interval_v1: 0.3452\n",
      "  order_v1: 0.1653\n",
      "  rally_v1: 0.2686\n",
      "\n",
      "Ridge回帰:\n",
      "  切片: 2.5250\n",
      "  1-distance_v1: 0.2543\n",
      "  1-interval_v1: 0.3270\n",
      "  order_v1: 0.1556\n",
      "  rally_v1: 0.2531\n",
      "\n",
      "Lasso回帰:\n",
      "  切片: 2.5250\n",
      "  1-distance_v1: 0.2576\n",
      "  1-interval_v1: 0.3352\n",
      "  order_v1: 0.1520\n",
      "  rally_v1: 0.2547\n",
      "\n",
      "===== 予測精度の詳細分析 =====\n",
      "最も精度の高いモデル: 重回帰分析\n",
      "重回帰分析の相関係数: 0.7284\n",
      "Ridge回帰の相関係数: 0.7241\n",
      "Lasso回帰の相関係数: 0.7194\n",
      "\n",
      "===== 予測誤差の分析 =====\n",
      "平均誤差: 0.0295\n",
      "誤差の標準偏差: 0.4285\n",
      "最大過大評価: 1.0557\n",
      "最大過小評価: -0.8424\n",
      "\n",
      "===== 特徴量の重要度 =====\n",
      "1-distance_v1: 0.254\n",
      "1-interval_v1: 0.330\n",
      "order_v1: 0.158\n",
      "rally_v1: 0.257\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CSVファイルを読み込み\n",
    "# df = pd.read_csv('../data/src/structural-features.csv')\n",
    "df = pd.read_csv('motion_title_content_with_graphs-gpt-a.csv')\n",
    "\n",
    "# 特徴量と目的変数を分離\n",
    "feature_columns = ['1-distance_v1', '1-interval_v1', 'order_v1', 'rally_v1']\n",
    "X = df[feature_columns]\n",
    "y = df['average_evaluation']\n",
    "\n",
    "print(\"===== データ概要 =====\")\n",
    "print(f\"サンプル数: {len(df)}\")\n",
    "print(f\"特徴量: {feature_columns}\")\n",
    "print(f\"\\n評価値の分布:\")\n",
    "print(f\"平均: {y.mean():.3f}\")\n",
    "print(f\"標準偏差: {y.std():.3f}\")\n",
    "print(f\"最小値: {y.min():.3f}\")\n",
    "print(f\"最大値: {y.max():.3f}\")\n",
    "\n",
    "# Leave-One-Out交差検証の準備\n",
    "loo = LeaveOneOut()\n",
    "n_samples = len(X)\n",
    "\n",
    "# 各モデルの結果を格納する辞書\n",
    "results = {\n",
    "    '重回帰分析': {'predictions': [], 'model': LinearRegression()},\n",
    "    'Ridge回帰': {'predictions': [], 'model': Ridge(alpha=1.0)},\n",
    "    'Lasso回帰': {'predictions': [], 'model': Lasso(alpha=0.01)}\n",
    "}\n",
    "\n",
    "# 標準化のためのスケーラー\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Leave-One-Out交差検証の実行\n",
    "print(\"\\n===== Leave-One-Out交差検証実行中 =====\")\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # データの標準化\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 各モデルで学習と予測\n",
    "    for model_name, model_info in results.items():\n",
    "        model = model_info['model']\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        model_info['predictions'].append(y_pred[0])\n",
    "\n",
    "# 評価指標の計算\n",
    "print(\"\\n===== 各モデルの性能評価 =====\")\n",
    "print(f\"{'モデル':<15} {'RMSE':<10} {'MAE':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for model_name, model_info in results.items():\n",
    "    predictions = np.array(model_info['predictions'])\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    \n",
    "    print(f\"{model_name:<15} {rmse:<10.4f} {mae:<10.4f}\")\n",
    "    \n",
    "    # 結果を保存\n",
    "    model_info['rmse'] = rmse\n",
    "    model_info['mae'] = mae\n",
    "\n",
    "# 全データで各モデルを学習して係数を確認\n",
    "print(\"\\n===== 各特徴量の回帰係数 =====\")\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "for model_name, model_info in results.items():\n",
    "    model = model_info['model']\n",
    "    model.fit(X_scaled, y)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  切片: {model.intercept_:.4f}\")\n",
    "    for i, feature in enumerate(feature_columns):\n",
    "        print(f\"  {feature}: {model.coef_[i]:.4f}\")\n",
    "\n",
    "# 予測値と実測値の相関\n",
    "print(\"\\n===== 予測精度の詳細分析 =====\")\n",
    "best_model_name = min(results, key=lambda x: results[x]['rmse'])\n",
    "print(f\"最も精度の高いモデル: {best_model_name}\")\n",
    "\n",
    "# 実測値と予測値の相関係数\n",
    "for model_name, model_info in results.items():\n",
    "    predictions = np.array(model_info['predictions'])\n",
    "    correlation = np.corrcoef(y, predictions)[0, 1]\n",
    "    print(f\"{model_name}の相関係数: {correlation:.4f}\")\n",
    "\n",
    "# 予測誤差の分析\n",
    "print(\"\\n===== 予測誤差の分析 =====\")\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "errors = y - best_predictions\n",
    "\n",
    "print(f\"平均誤差: {np.mean(errors):.4f}\")\n",
    "print(f\"誤差の標準偏差: {np.std(errors):.4f}\")\n",
    "print(f\"最大過大評価: {np.max(errors):.4f}\")\n",
    "print(f\"最大過小評価: {np.min(errors):.4f}\")\n",
    "\n",
    "# 各特徴量の重要度（標準化後の係数の絶対値）\n",
    "print(\"\\n===== 特徴量の重要度 =====\")\n",
    "model = results['重回帰分析']['model']\n",
    "model.fit(X_scaled, y)\n",
    "feature_importance = np.abs(model.coef_)\n",
    "feature_importance_normalized = feature_importance / np.sum(feature_importance)\n",
    "\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    print(f\"{feature}: {feature_importance_normalized[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
